{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow_core.python.keras.utils import np_utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import datetime\n",
    "import random\n",
    "random.seed(42)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"my mobilenet_7.h5 path\" #Â Replace this\n",
    "model = load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Download video\n",
    "youtube-dl \"https://www.youtube.com/watch?v=O9uvBFovKj8\"\n",
    "\n",
    "# Download audio track\n",
    "youtube-dl -f bestaudio --extract-audio --audio-format wav --audio-quality 0 \"https://www.youtube.com/watch?v=O9uvBFovKj8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAVE_FILE_PATH = \"Driving Fails Compilation - Episode #180 HD-uFwnmh0GpBo.wav\"\n",
    "\n",
    "conf={}\n",
    "conf['sampling_rate'] = 22050\n",
    "conf['duration'] = 1  # 4\n",
    "conf['hop_length'] = 128\n",
    "conf['fmin'] = 20\n",
    "conf['fmax'] = conf['sampling_rate'] // 2\n",
    "conf['n_mels'] = 128  # 128\n",
    "conf['n_fft'] = 1024\n",
    "conf['audio_split'] = 'head'\n",
    "\n",
    "categories_dictionary = {'driving':0,\n",
    "                         'crash':1,\n",
    "                         'horn':2,\n",
    "                         'music':3,\n",
    "                         'talking':4,\n",
    "                         'tire':5,\n",
    "                         'scream':6\n",
    "                         }\n",
    "all_categories_list = categories_dictionary.keys()\n",
    "inv_map = {v: k for k, v in categories_dictionary.items()}  # inverse of category_dictionary (ClassNumber:ClassName)\n",
    "\n",
    "frames = 51\n",
    "FRAMES_PER_SEGMENT = frames - 1\n",
    "WINDOW_SIZE = 256 * FRAMES_PER_SEGMENT   # 256*50=12800 circa 0.5sec a 22050 hz\n",
    "STEP_SIZE = 256 * FRAMES_PER_SEGMENT // 2\n",
    "\n",
    "def get_X_from_signal(signal, conf):\n",
    "    spectrogram = librosa.feature.melspectrogram(signal, \n",
    "                                                 sr=conf['sampling_rate'],\n",
    "                                                 n_mels=conf['n_mels'],\n",
    "                                                 n_fft=1024,\n",
    "                                                 hop_length=128,\n",
    "                                                 fmin=conf['fmin'],  # 1024,128 -> 128x101\n",
    "                                                 fmax=conf['fmax'])\n",
    "    spectrogram = librosa.power_to_db(spectrogram)\n",
    "    spectrogram = spectrogram.astype(np.float32)\n",
    "    return spectrogram\n",
    "\n",
    "\n",
    "def get_normalized_clip(filename):\n",
    "    new_clip, sr = librosa.load(filename)\n",
    "    new_clip = librosa.resample(new_clip, sr, conf['sampling_rate'])\n",
    "    normalization_factor = 1 / np.max(np.abs(new_clip))\n",
    "    return new_clip * normalization_factor\n",
    "    \n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    samplewise_center=True,  # Set each sample mean to 0\n",
    "    samplewise_std_normalization=True  #D ivide each input by its std.\n",
    ")\n",
    "output_dataset = pd.DataFrame()\n",
    "new_clip = get_normalized_clip(WAVE_FILE_PATH)\n",
    "s = 0\n",
    "while len(new_clip[s * STEP_SIZE:s * STEP_SIZE + WINDOW_SIZE]) == WINDOW_SIZE:\n",
    "    d = {}\n",
    "    signal = new_clip[s * STEP_SIZE:s * STEP_SIZE + WINDOW_SIZE]\n",
    "    new_x = np.expand_dims(get_X_from_signal(signal, conf), axis=-1)\n",
    "    d['X'] = new_x\n",
    "    X = np.asarray(np.dstack([new_x[:,:,0], librosa.feature.delta(new_x[:,:,0], order=1), librosa.feature.delta(new_x[:,:,0], order=2)]))\n",
    "    predictions = model.predict(np.expand_dims(datagen.standardize(X), axis=0))\n",
    "    prediction = np.argmax(predictions)\n",
    "    d['predictions'] = predictions\n",
    "    d['prediction'] = prediction\n",
    "    d['timestamp'] = str(datetime.timedelta(seconds=(s*STEP_SIZE/conf['sampling_rate'])))\n",
    "    output_dataset = output_dataset.append(d, ignore_index=True)\n",
    "    s = s + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subtitle_file(output_dataset, output_subtitle_file, sampling_freq):\n",
    "    import re\n",
    "    import datetime\n",
    "    inv_map = {v: k for k, v in categories_dictionary.items()}  # inverse of category_dictionary {ClassNumber:ClassName}\n",
    "    PROBABILITY_THRESHOLD = 0.6\n",
    "    \n",
    "    with open(output_subtitle_file, \"a\") as sub_file:\n",
    "        for index, row in output_dataset.iterrows():\n",
    "            max_probability = np.max(row['predictions'][0])\n",
    "            sub_file.write('{}\\n'.format(index+1))\n",
    "            sub_file.write('{} --> {}\\n'.format(re.sub(r\"(\\.\\d{3})\\d{3}\", r'\\1', str(datetime.timedelta(seconds=(index*STEP_SIZE/sampling_freq)))), \n",
    "                                                re.sub(r\"(\\.\\d{3})\\d{3}\", r'\\1',str(datetime.timedelta(seconds=(((index+1)*STEP_SIZE))/sampling_freq)))))\n",
    "            if max_probability >= PROBABILITY_THRESHOLD:\n",
    "                if(row['prediction'] == 1):\n",
    "                    sub_file.write('<b><font color=\"#ff0000\">{}</font></b>'.format(inv_map[row['prediction']]))\n",
    "                else:\n",
    "                    sub_file.write('{}'.format(inv_map[row['prediction']]))\n",
    "\n",
    "            # other predictions with probability\n",
    "            prob_string = []\n",
    "            for prob in row['predictions'][0]:\n",
    "                prob_string.append('{}:{:.2f}'.format(inv_map[list(row['predictions'][0]).index(prob)], prob))\n",
    "            sub_file.write('\\n<font size=\"12\">{}</font>'.format(' '.join(prob_string)))\n",
    "            # closing the file\n",
    "            sub_file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_subtitle_file(output_dataset, \"subtitle.srt path\", 22050)"
   ]
  }
 ]
}
